use crate::server::HashDiscovered;
use crate::types::TorrentInfo;
use crate::metadata::RbitFetcher;
use std::sync::{Arc, RwLock};
use std::sync::atomic::{AtomicU64, AtomicUsize, Ordering};
use tokio::sync::{mpsc, Mutex};
#[cfg(debug_assertions)]
use std::time::Duration;

type TorrentCallback = Arc<dyn Fn(TorrentInfo) + Send + Sync>;
type MetadataFetchCallback = Arc<dyn Fn(String) -> std::pin::Pin<Box<dyn std::future::Future<Output = bool> + Send>> + Send + Sync>;

/// å…ƒæ•°æ®è°ƒåº¦å™¨ï¼ˆä¼˜é›…ç‰ˆï¼šWorker æ±  + Channelï¼‰
/// è´Ÿè´£ç®¡ç†å…ƒæ•°æ®è·å–é˜Ÿåˆ—å’Œä»»åŠ¡è°ƒåº¦
pub struct MetadataScheduler {
    // è¾“å…¥é€šé“
    hash_rx: mpsc::Receiver<HashDiscovered>,
    
    // é…ç½®
    max_queue_size: usize,
    max_concurrent: usize,
    
    // å…ƒæ•°æ®è·å–å™¨
    fetcher: Arc<RbitFetcher>,
    
    // å›è°ƒ
    callback: Arc<RwLock<Option<TorrentCallback>>>,
    on_metadata_fetch: Arc<RwLock<Option<MetadataFetchCallback>>>,
    
    // ç»Ÿè®¡ï¼ˆä½¿ç”¨ Atomic æ”¯æŒå¤šçº¿ç¨‹è®¿é—®ï¼‰
    total_received: Arc<AtomicU64>,
    total_dropped: Arc<AtomicU64>,
    total_dispatched: Arc<AtomicU64>,
    
    // å…±äº«çš„é˜Ÿåˆ—é•¿åº¦è®¡æ•°å™¨ï¼ˆç”¨äºå‘ Server åé¦ˆèƒŒå‹ï¼‰
    queue_len: Arc<AtomicUsize>,
}

impl MetadataScheduler {
    pub fn new(
        hash_rx: mpsc::Receiver<HashDiscovered>,
        fetcher: Arc<RbitFetcher>,
        max_queue_size: usize,
        max_concurrent: usize,
        callback: Arc<RwLock<Option<TorrentCallback>>>,
        on_metadata_fetch: Arc<RwLock<Option<MetadataFetchCallback>>>,
        queue_len: Arc<AtomicUsize>, // æ–°å¢å‚æ•°
    ) -> Self {
        Self {
            hash_rx,
            max_queue_size,
            max_concurrent,
            fetcher,
            callback,
            on_metadata_fetch,
            total_received: Arc::new(AtomicU64::new(0)),
            total_dropped: Arc::new(AtomicU64::new(0)),
            total_dispatched: Arc::new(AtomicU64::new(0)),
            queue_len,
        }
    }
    
    /// è®¾ç½® torrent å›è°ƒ
    pub fn set_callback(&mut self, callback: TorrentCallback) {
        if let Ok(mut guard) = self.callback.try_write() {
            *guard = Some(callback);
        }
    }
    
    /// è®¾ç½®å…ƒæ•°æ®è·å–å‰çš„æ£€æŸ¥å›è°ƒ
    pub fn set_metadata_fetch_callback(&mut self, callback: MetadataFetchCallback) {
        if let Ok(mut guard) = self.on_metadata_fetch.try_write() {
            *guard = Some(callback);
        }
    }
    
    /// è¿è¡Œè°ƒåº¦å™¨ï¼ˆå®Œå…¨äº‹ä»¶é©±åŠ¨ï¼‰
    pub async fn run(mut self) {        
        // åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—ï¼ˆchannel è‡ªå¸¦èƒŒå‹ï¼‰
        let (task_tx, task_rx) = mpsc::channel::<HashDiscovered>(self.max_queue_size);
        let task_rx = Arc::new(Mutex::new(task_rx));
        
        // å¯åŠ¨ Worker æ± 
        for worker_id in 0..self.max_concurrent {
            let task_rx = task_rx.clone();
            let fetcher = self.fetcher.clone();
            let callback = self.callback.clone();
            let on_metadata_fetch = self.on_metadata_fetch.clone();
            let total_dispatched = self.total_dispatched.clone();
            let queue_len = self.queue_len.clone(); // ä¼ é€’è®¡æ•°å™¨
            
            tokio::spawn(async move {
                log::trace!("Worker {} å¯åŠ¨", worker_id);
                
                loop {
                    // Worker ä»é˜Ÿåˆ—å–ä»»åŠ¡ï¼ˆé˜»å¡ç­‰å¾…ï¼Œé›¶å»¶è¿Ÿï¼‰
                    let hash = {
                        let mut rx = task_rx.lock().await;
                        let h = rx.recv().await;
                        // å–å‡ºä»»åŠ¡åï¼Œå‡å°‘è®¡æ•°å™¨
                        if h.is_some() {
                            queue_len.fetch_sub(1, Ordering::Relaxed);
                        }
                        h
                    };
                    
                    let hash = match hash {
                        Some(h) => h,
                        None => break,  // Channel å…³é—­ï¼Œé€€å‡º
                    };
                    
                    total_dispatched.fetch_add(1, Ordering::Relaxed);
                    
                    // æ‰§è¡Œä»»åŠ¡
                    Self::process_hash(
                        hash,
                        &fetcher,
                        &callback,
                        &on_metadata_fetch,
                    ).await;
                }
                
                log::trace!("Worker {} é€€å‡º", worker_id);
            });
        }
        
        // ä¸»å¾ªç¯ï¼šåªè´Ÿè´£æ¥æ”¶ hash å¹¶è½¬å‘åˆ° worker é˜Ÿåˆ—
        #[cfg(debug_assertions)]
        let mut stats_interval = tokio::time::interval(Duration::from_secs(60));
        #[cfg(debug_assertions)]
        stats_interval.tick().await;
        
        loop {
            #[cfg(debug_assertions)]
            {
                tokio::select! {
                    Some(hash) = self.hash_rx.recv() => {
                        self.total_received.fetch_add(1, Ordering::Relaxed);
                        
                        // å°è¯•å‘é€åˆ° worker é˜Ÿåˆ—
                        match task_tx.try_send(hash) {
                            Ok(_) => {
                                // æˆåŠŸå…¥é˜Ÿï¼Œå¢åŠ è®¡æ•°å™¨
                                self.queue_len.fetch_add(1, Ordering::Relaxed);
                            }
                            Err(mpsc::error::TrySendError::Full(_)) => {
                                // é˜Ÿåˆ—æ»¡ï¼Œä¸¢å¼ƒ
                                self.total_dropped.fetch_add(1, Ordering::Relaxed);
                            }
                            Err(_) => break,  // Channel å…³é—­
                        }
                    }
                    
                    _ = stats_interval.tick() => {
                        self.print_stats(&task_tx);
                    }
                    
                    else => break,
                }
            }
            
            #[cfg(not(debug_assertions))]
            {
                match self.hash_rx.recv().await {
                    Some(hash) => {
                        self.total_received.fetch_add(1, Ordering::Relaxed);
                        
                        // å°è¯•å‘é€åˆ° worker é˜Ÿåˆ—
                        match task_tx.try_send(hash) {
                            Ok(_) => {
                                // æˆåŠŸå…¥é˜Ÿï¼Œå¢åŠ è®¡æ•°å™¨
                                self.queue_len.fetch_add(1, Ordering::Relaxed);
                            }
                            Err(mpsc::error::TrySendError::Full(_)) => {
                                // é˜Ÿåˆ—æ»¡ï¼Œä¸¢å¼ƒ
                                self.total_dropped.fetch_add(1, Ordering::Relaxed);
                            }
                            Err(_) => break,  // Channel å…³é—­
                        }
                    }
                    None => break,  // Channel å…³é—­
                }
            }
        }
    }
    
    /// å¤„ç†å•ä¸ª hashï¼ˆWorker è°ƒç”¨ï¼‰
    async fn process_hash(
        hash: HashDiscovered,
        fetcher: &Arc<RbitFetcher>,
        callback: &Arc<RwLock<Option<TorrentCallback>>>,
        on_metadata_fetch: &Arc<RwLock<Option<MetadataFetchCallback>>>,
    ) {
        let info_hash = hash.info_hash.clone();
        let peer_addr = hash.peer_addr;
        
        // æ£€æŸ¥æ˜¯å¦éœ€è¦è·å–ï¼ˆè·å–å›è°ƒå¿«ç…§å¹¶é‡Šæ”¾é”ï¼‰
        let maybe_check_fn = {
            match on_metadata_fetch.read() {
                Ok(guard) => guard.clone(),
                Err(_) => return, // é”ä¸­æ¯’
            }
        };

        if let Some(f) = maybe_check_fn {
            if !f(info_hash.clone()).await {
                return;
            }
        }
        
        // è§£ç  info_hash
        let info_hash_bytes: [u8; 20] = match hex::decode(&info_hash) {
            Ok(bytes) if bytes.len() == 20 => {
                let mut arr = [0u8; 20];
                arr.copy_from_slice(&bytes);
                arr
            }
            _ => return,
        };
        
        // è·å–å…ƒæ•°æ®
        if let Some((name, total_size, files)) = fetcher.fetch(&info_hash_bytes, peer_addr).await {
            let metadata = TorrentInfo {
                info_hash,
                name,
                total_size,
                files,
                magnet_link: format!("magnet:?xt=urn:btih:{}", hash.info_hash),
                peers: vec![peer_addr.to_string()],
                piece_length: 0,
                timestamp: std::time::SystemTime::now()
                    .duration_since(std::time::UNIX_EPOCH)
                    .unwrap()
                    .as_secs(),
            };
            
            // è·å–å›è°ƒå¿«ç…§å¹¶é‡Šæ”¾é”
            let maybe_torrent_cb = {
                match callback.read() {
                    Ok(guard) => guard.clone(),
                    Err(_) => return, // é”ä¸­æ¯’
                }
            };
            
            if let Some(cb) = maybe_torrent_cb {
                cb(metadata);
            }
        }
    }
    
    /// è¾“å‡ºç»Ÿè®¡ä¿¡æ¯ï¼ˆä»…åœ¨ debug æ¨¡å¼ä¸‹ç¼–è¯‘ï¼‰
    #[cfg(debug_assertions)]
    fn print_stats(&self, task_tx: &mpsc::Sender<HashDiscovered>) {
        let received = self.total_received.load(Ordering::Relaxed);
        let dropped = self.total_dropped.load(Ordering::Relaxed);
        let dispatched = self.total_dispatched.load(Ordering::Relaxed);
        
        let drop_rate = if received > 0 {
            dropped as f64 / received as f64 * 100.0
        } else {
            0.0
        };
        
        let queue_size = self.max_queue_size - task_tx.capacity();
        let queue_pressure = (queue_size as f64 / self.max_queue_size as f64) * 100.0;
        
        // æ ¹æ®å‹åŠ›é€‰æ‹©æ—¥å¿—çº§åˆ«
        if queue_pressure > 80.0 {
            log::warn!(
                "âš ï¸ Metadata é˜Ÿåˆ—é«˜å‹ï¼šé˜Ÿåˆ—={}/{}({:.1}%), æ¥æ”¶={}, è°ƒåº¦={}, ä¸¢å¼ƒ={}({:.2}%)",
                queue_size,
                self.max_queue_size,
                queue_pressure,
                received,
                dispatched,
                dropped,
                drop_rate
            );
        } else {
            log::info!(
                "ğŸ“Š Metadata è°ƒåº¦å™¨ç»Ÿè®¡ï¼šé˜Ÿåˆ—={}/{}({:.1}%), æ¥æ”¶={}, è°ƒåº¦={}, ä¸¢å¼ƒ={}({:.2}%)",
                queue_size,
                self.max_queue_size,
                queue_pressure,
                received,
                dispatched,
                dropped,
                drop_rate
            );
        }
    }
}
